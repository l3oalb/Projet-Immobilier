{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c41b7be8",
   "metadata": {},
   "source": [
    "Suite projet immobilier pour le devoir SQL/NOSQL\n",
    "\n",
    "à l'aide de PySpark : créer les tables et/ou collections permettant l'organisation de la donnée la plus adaptée aux besoins du projet choisi, préconisée lors de la première restitution( 5 points ) ; écrire les processus PySpark d'import et enregistrement de la donnée, depuis les sources OpenData identifiées( 5 points ) ; stocker la donnée sur HDFS ou MongoDB( facultatif, 2 points ).\n",
    "\n",
    "Suite : comparer prix des annonces web scrapées en ligne avec les données du dataset DVF de datagouv pour décider si l'annonce vaut le coup ou non. Si elle vaut le coiup, un mail sera envoyé à l'utilisateur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f091e2fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import DoubleType\n",
    "\n",
    "# Objectif : Source (CSV) -> PySpark (Nettoyage) -> HDFS/Mongo (Stockage) -> Streamlit (Visualisation).\n",
    "\n",
    "# 1. INITIALISATION (Obligatoire pour PySpark)\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"AnalyseImmobilier\") \\\n",
    "    .config(\"spark.mongodb.output.uri\", \"mongodb://127.0.0.1/immo_db.tendances\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "def processus_etl(chemin_csv):\n",
    "    # 2. IMPORT (5 points)\n",
    "    # On utilise Spark pour lire le fichier avec le séparateur '|'\n",
    "    df = spark.read.options(header='true', sep='|', inferSchema='true').csv(\"ton_fichier.txt\")\n",
    "\n",
    "    # 3. NETTOYAGE & TRANSFORMATION (Organisation de la donnée)\n",
    "    # On caste les types pour les calculs\n",
    "    df_clean = df.withColumn(\"Valeur fonciere\", F.col(\"Valeur fonciere\").cast(\"double\")) \\\n",
    "                 .withColumn(\"Surface reelle bati\", F.col(\"Surface reelle bati\").cast(\"double\")) \\\n",
    "                 .withColumn(\"Date mutation\", F.to_date(F.col(\"Date mutation\"), \"dd/MM/yyyy\"))\n",
    "\n",
    "    # Filtres métier (comme dans ton code Pandas)\n",
    "    df_filtered = df_clean.filter(\n",
    "        (F.col(\"Nature mutation\") == \"Vente\") &\n",
    "        (F.col(\"Type local\").isin(\"Maison\", \"Appartement\")) &\n",
    "        (F.col(\"Surface reelle bati\") > 9) &\n",
    "        (F.col(\"Valeur fonciere\") > 1000)\n",
    "    ).dropna(subset=[\"Valeur fonciere\", \"Surface reelle bati\"])\n",
    "\n",
    "    # 4. CALCUL DES KPIS (Table Gold / Tendances)\n",
    "    # Calcul du prix au m2\n",
    "    df_final = df_filtered.withColumn(\"prix_m2\", F.col(\"Valeur fonciere\") / F.col(\"Surface reelle bati\"))\n",
    "    \n",
    "    # Filtre des aberrations\n",
    "    df_final = df_final.filter((F.col(\"prix_m2\") > 500) & (F.col(\"prix_m2\") < 15000))\n",
    "\n",
    "    # Agrégation par Commune (pour tes tendances)\n",
    "    df_communes = df_final.groupBy(\"Code departement\", \"Commune\").agg(\n",
    "        F.median(\"prix_m2\").alias(\"prix_median\"),\n",
    "        F.count(\"Valeur fonciere\").alias(\"nb_ventes\")\n",
    "    )\n",
    "\n",
    "    # 5. STOCKAGE (2 points facultatifs)\n",
    "    # Sauvegarde sur HDFS au format Parquet (plus performant que CSV)\n",
    "    df_communes.write.mode(\"overwrite\").parquet(\"hdfs:///user/data/immo_final\")\n",
    "    \n",
    "    # OU Sauvegarde vers MongoDB\n",
    "    # df_communes.write.format(\"mongodb\").mode(\"append\").save()\n",
    "\n",
    "    return df_communes\n",
    "\n",
    "# Lancement\n",
    "import os\n",
    "dossier = \"/Data\"  # Liste des fichiers à traiter\n",
    "for fichier in os.listdir(dossier):\n",
    "    fichier = os.path.join(dossier, fichier)\n",
    "    if fichier.endswith('.txt'):\n",
    "        processus_etl(fichier).show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
