# ğŸ  Projet Analyse ImmobiliÃ¨re

SystÃ¨me intelligent d'analyse du marchÃ© immobilier franÃ§ais combinant donnÃ©es DVF (Demandes de Valeurs FonciÃ¨res), web scraping d'annonces en temps rÃ©el, et intelligence artificielle pour dÃ©tecter les opportunitÃ©s immobiliÃ¨res.

## ğŸ“‹ Vue d'ensemble

Ce projet combine trois composants principaux :

1. **Pipeline ETL** : Traitement des donnÃ©es DVF avec PySpark pour calculer les prix mÃ©dians au mÂ² par commune
2. **Scraper intelligent** : RÃ©cupÃ©ration et analyse d'annonces immobiliÃ¨res en temps rÃ©el avec IA
3. **Dashboard** : Visualisation interactive des tendances du marchÃ© avec Streamlit

## ğŸ¯ FonctionnalitÃ©s

### ğŸ“Š Analyse des donnÃ©es DVF
- Import et traitement de fichiers DVF (transactions immobiliÃ¨res officielles)
- Calcul des prix mÃ©dians au mÂ² par commune et par annÃ©e (2020-2024)
- Filtrage intelligent (ventes uniquement, surfaces cohÃ©rentes, prix rÃ©alistes)
- Stockage dans MongoDB pour analyse rapide

### ğŸ” Scraping et dÃ©tection d'opportunitÃ©s
- Recherche d'annonces rÃ©centes via Google (API Serper)
- Extraction du contenu des annonces (Jina AI Reader)
- Extraction intelligente des informations (OpenAI GPT-4o-mini) :
  - Prix, surface, type de bien
  - Localisation, Ã©tat du bien
- Enrichissement gÃ©ographique :
  - GÃ©ocodage (API data.gouv.fr)
  - Analyse de l'environnement (OpenStreetMap) :
    - Distance aux transports en commun
    - ProximitÃ© des commerces, Ã©coles, parcs
    - Distance aux routes principales (nuisances)
- Comparaison avec les prix DVF pour dÃ©tecter les bonnes affaires

### ğŸ“ˆ Visualisation
- Dashboard interactif Streamlit
- Top 10 des communes avec les plus fortes hausses de prix
- Ã‰volution historique du prix au mÂ² par commune
- Graphiques interactifs (Plotly)

## ğŸ› ï¸ Technologies

- **Python 3.11+**
- **PySpark** : Traitement distribuÃ© des donnÃ©es DVF
- **MongoDB** : Base de donnÃ©es NoSQL pour les tendances
- **Streamlit** : Interface web interactive
- **OpenAI API** : Extraction d'informations structurÃ©es
- **Jina AI Reader** : Scraping web sans blocage
- **Serper API** : Recherche Google
- **APIs externes** :
  - data.gouv.fr (gÃ©ocodage)
  - OpenStreetMap/Overpass API (POI)

## ğŸ“¦ Installation

### PrÃ©requis
- Python 3.11+
- uv (gestionnaire de paquets Python moderne)
- AccÃ¨s MongoDB (local ou Atlas)

### Configuration

1. **Cloner le projet**
```bash
git clone <votre-repo>
cd Projet-Immobilier
```

2. **Installer les dÃ©pendances avec uv**
```bash
uv sync
```

3. **Configuration des variables d'environnement**

CrÃ©ez un fichier `.env` Ã  la racine :
```env
MONGO_URI=mongodb+srv://user:password@cluster.mongodb.net/
OPENAI_API_KEY=sk-...
SERPER_API_KEY=...
```

4. **TÃ©lÃ©charger les donnÃ©es DVF**

TÃ©lÃ©chargez les fichiers depuis [data.gouv.fr](https://www.data.gouv.fr/fr/datasets/demandes-de-valeurs-foncieres/) et placez-les dans le dossier `Data/`.

## ğŸš€ Utilisation

### 1. Traitement des donnÃ©es DVF

```bash
python -m projet_immobilier.etl
```

Ce script :
- Lit tous les fichiers `.txt` du dossier `Data/`
- Calcule les prix mÃ©dians au mÂ² par commune et annÃ©e
- Stocke les rÃ©sultats dans MongoDB

**Note** : Vous pouvez aussi utiliser `uv run -m projet_immobilier.etl` si vous utilisez uv.

### 2. Scraping et analyse d'annonces

```bash
python main_scraper.py
```

Ce script :
- Recherche des annonces rÃ©centes (derniÃ¨res 24h)
- Extrait les informations avec l'IA
- Enrichit avec les donnÃ©es gÃ©ographiques
- Compare avec les prix DVF
- Affiche les opportunitÃ©s dÃ©tectÃ©es

**Exemple de sortie** :
```
ğŸšŒ Transport : 150m vers l'arrÃªt le plus proche
ğŸ  Bien : Appartement Ã  NANTES
ğŸ’° Prix IA : 250000â‚¬ pour 65m2 (3846â‚¬/m2)
ğŸ“Š Verdict : âœ… BON PRIX (Sous la mÃ©diane) (Ecart : -12.5%)
```

### 3. Dashboard de visualisation

```bash
streamlit run app.py
```

Ouvre le dashboard dans votre navigateur pour :
- Explorer les Ã©volutions de prix par dÃ©partement
- Analyser les tendances par commune
- Visualiser les historiques de prix

## ğŸ“ Structure du projet

```
Projet-Immobilier/
â”œâ”€â”€ app.py                              # Dashboard Streamlit
â”œâ”€â”€ main_scraper.py                     # Orchestrateur principal (point d'entrÃ©e)
â”œâ”€â”€ projet_immobilier/                  # Package Python principal
â”‚   â”œâ”€â”€ __init__.py                     # Initialisation du package
â”‚   â”œâ”€â”€ etl.py                          # Pipeline ETL PySpark â†’ MongoDB
â”‚   â”œâ”€â”€ decision.py                     # Moteur de dÃ©cision (opportunitÃ©s)
â”‚   â”œâ”€â”€ jina_web_scraper.py             # Scraping d'annonces
â”‚   â”œâ”€â”€ extract_with_gen_ai.py          # Extraction IA (OpenAI)
â”‚   â”œâ”€â”€ extract_with_regex.py           # Extraction regex (fallback)
â”‚   â”œâ”€â”€ get_coord_API.py                # GÃ©ocodage
â”‚   â””â”€â”€ get_additionals_informations.py # Enrichissement environnemental
â”œâ”€â”€ Data/                               # Fichiers DVF (non versionnÃ©s)
â”œâ”€â”€ pyproject.toml                      # Configuration uv
â”œâ”€â”€ uv.lock                             # Fichier de lock des dÃ©pendances
â””â”€â”€ .env                                # Variables d'environnement (non versionnÃ©)
```

## ğŸ”§ Configuration avancÃ©e

### Personnaliser les critÃ¨res de filtrage (projet_immobilier/etl.py)

```python
# Ligne 29-35 : Ajustez les filtres DVF
df_filtered = df_clean.filter(
    (F.col("Nature mutation") == "Vente") &
    (F.col("Type local").isin("Maison", "Appartement")) &
    (F.col("surface_bati") > 15) &  # Surface minimale
    (F.col("valeur_fonciere") > 20000) &  # Prix minimum
    (F.col("annee").isNotNull())
)
```

### Modifier les critÃ¨res d'opportunitÃ© (projet_immobilier/decision.py)

```python
# Ligne 33-40 : Ajustez les seuils
if difference <= -15:
    verdict = "ğŸ”¥ EXCELLENTE AFFAIRE"
elif difference <= 0:
    verdict = "âœ… BON PRIX"
elif difference <= 15:
    verdict = "âš–ï¸ PRIX DE MARCHÃ‰"
else:
    verdict = "âŒ TROP CHER"
```

### ParamÃ©trer la recherche (main_scraper.py)

```python
# Ligne 8 : Modifiez la ville et la surface recherchÃ©e
ads_data = get_latest_ads_content("Nantes", "50")
```

## ğŸ” SÃ©curitÃ©

âš ï¸ **Important** :
- Ne committez JAMAIS le fichier `.env`
- Utilisez des variables d'environnement pour les clÃ©s API
- Limitez les permissions MongoDB (lecture/Ã©criture uniquement)
- Respectez les quotas des APIs (Serper, OpenAI, Overpass)

## ğŸ“Š Exemple de workflow complet

1. **Initialisation** : Traiter les donnÃ©es DVF historiques
```bash
python -m projet_immobilier.etl
```

2. **Monitoring quotidien** : Lancer le scraper (peut Ãªtre automatisÃ© avec cron)
```bash
python main_scraper.py
```

3. **Analyse** : Consulter le dashboard pour les tendances
```bash
streamlit run app.py
```

## ğŸ› DÃ©pannage

### Erreur MongoDB
```
âš ï¸ Erreur de stockage : ServerSelectionTimeoutError
```
â†’ VÃ©rifiez votre `MONGO_URI` et la connexion rÃ©seau

### Timeout Jina/Serper
```
Erreur Jina : timeout
```
â†’ Augmentez le timeout dans `projet_immobilier/jina_web_scraper.py` ligne 47

### Erreur OpenAI
```
openai.error.RateLimitError
```
â†’ VÃ©rifiez vos crÃ©dits API et respectez les limites de taux

## ğŸš€ AmÃ©liorations futures

- [ ] Ajouter des tests unitaires
- [ ] CrÃ©er une API REST (FastAPI)
- [ ] SystÃ¨me de notifications (email/Telegram)
- [ ] Support multi-rÃ©gions
- [ ] Cache des rÃ©sultats de gÃ©ocodage
- [ ] Interface d'administration MongoDB
- [ ] Export des rÃ©sultats (PDF, Excel)
- [ ] IntÃ©gration d'autres sources de donnÃ©es

